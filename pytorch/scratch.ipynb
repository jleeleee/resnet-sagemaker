{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S3OutputPath': 's3://path/for/data/emission', 'LocalPath': '/local/path/for/data/emission', 'HookParameters': {'save_interval': '10'}, 'CollectionConfigurations': [{'CollectionName': 'all'}]}\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig\n",
    "collection_config_1 = CollectionConfig(name='all')\n",
    "d = DebuggerHookConfig(\n",
    "    s3_output_path='s3://path/for/data/emission',\n",
    "    container_local_output_path='/local/path/for/data/emission',\n",
    "    hook_parameters={\n",
    "        'save_interval': '10'\n",
    "    },\n",
    "    collection_configs=[\n",
    "        collection_config_1\n",
    "    ]\n",
    ")\n",
    "print(d._to_request_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import pytorch_lightning as pl\n",
    "import webdataset as wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-08 15:01:12.987 ip-172-31-93-109:2987 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-06-08 15:01:13.066 ip-172-31-93-109:2987 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "TEST :out_dir \n",
      "[2023-06-08 15:01:13.067 ip-172-31-93-109:2987 INFO hook.py:207] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2023-06-08 15:01:13.068 ip-172-31-93-109:2987 INFO hook.py:260] Saving to out_dir\n",
      "[2023-06-08 15:01:13.068 ip-172-31-93-109:2987 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "import smdebug.pytorch as smd\n",
    "hook = smd.Hook(\n",
    "    'out_dir',\n",
    "    export_tensorboard = False,\n",
    "    tensorboard_dir = None,\n",
    "    dry_run = False,\n",
    "    reduction_config = None,\n",
    "    save_config = None,\n",
    "    include_regex = None,\n",
    "    include_collections = None,\n",
    "    save_all = True,\n",
    "    include_workers=\"one\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-07 20:26:11.373 ip-172-31-93-109:94668 INFO local_trial.py:35] Loading trial  at path /home/ubuntu/resnet-sagemaker/pytorch/debugger_logs/\n"
     ]
    }
   ],
   "source": [
    "from smdebug.trials import create_trial\n",
    "from smdebug import modes\n",
    "smdebug_trial = create_trial(\"/home/ubuntu/resnet-sagemaker/pytorch/debugger_logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-07 20:26:12.196 ip-172-31-93-109:94668 INFO trial.py:197] Training has ended, will refresh one final time in 1 sec.\n",
      "[2023-06-07 20:26:13.197 ip-172-31-93-109:94668 INFO trial.py:210] Loaded all steps\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "for step in smdebug_trial.steps(mode=modes.TRAIN):\n",
    "    print(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLLLoss_output_0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smdebug_trial.tensor_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_classes, resnet_version,\n",
    "                 train_path, val_path, optimizer='adamw',\n",
    "                 lr=1e-3, batch_size=64,\n",
    "                 dataloader_workers=4, \n",
    "                 *args, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__dict__.update(locals())\n",
    "        \n",
    "        resnets = {\n",
    "            18:tv.models.resnet18,\n",
    "            34:tv.models.resnet34,\n",
    "            50:tv.models.resnet50,\n",
    "            101:tv.models.resnet101,\n",
    "            152:tv.models.resnet152\n",
    "        }\n",
    "        \n",
    "        optimizers = {\n",
    "            'adam': torch.optim.Adam,\n",
    "            'adamw': torch.optim.AdamW,\n",
    "            'sgd': torch.optim.SGD\n",
    "        }\n",
    "        \n",
    "        self.optimizer = optimizers[optimizer]\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.model = resnets[resnet_version]()\n",
    "        linear_size = list(self.model.children())[-1].in_features\n",
    "        self.model.fc = torch.nn.Linear(linear_size, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer(self.parameters(), lr=self.lr)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        preproc = tv.transforms.Compose([\n",
    "                tv.transforms.ToTensor(),\n",
    "                tv.transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                                        (0.229, 0.224, 0.225)),\n",
    "                tv.transforms.Resize((224, 224))\n",
    "            ])\n",
    "        dataset = wds.WebDataset(self.train_path, resampled=True).shuffle(1024) \\\n",
    "                        .decode(\"pil\").to_tuple(\"jpeg\", \"cls\").map_tuple(preproc, lambda x:x) \\\n",
    "                        .with_epoch(10000)\n",
    "        return wds.WebLoader(dataset, \n",
    "                                           num_workers=self.dataloader_workers, \n",
    "                                           batch_size=self.batch_size)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        preproc = tv.transforms.Compose([\n",
    "                tv.transforms.ToTensor(),\n",
    "                tv.transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                                        (0.229, 0.224, 0.225)),\n",
    "                tv.transforms.Resize((224, 224))\n",
    "            ])\n",
    "        dataset = wds.WebDataset(self.val_path, resampled=True).shuffle(1024) \\\n",
    "                        .decode(\"pil\").to_tuple(\"jpeg\", \"cls\").map_tuple(preproc, lambda x:x)\\\n",
    "                        .with_epoch(10000)\n",
    "        return wds.WebLoader(dataset, \n",
    "                                           num_workers=self.dataloader_workers, \n",
    "                                           batch_size=self.batch_size)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = self.criterion(preds, y)\n",
    "        acc = (y == torch.argmax(preds, 1)).type(torch.FloatTensor).mean()\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = self.criterion(preds, y)\n",
    "        acc = (y == torch.argmax(preds, 1)).type(torch.FloatTensor).mean()\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlSageMakerLogger(pl.Callback):\n",
    "    \n",
    "    def __init__(self, frequency=10):\n",
    "        self.frequency=frequency\n",
    "        self.step = 0\n",
    "        \n",
    "    def on_epoch_start(self, trainer, module, *args, **kwargs):\n",
    "        self.inner_step = 0\n",
    "    \n",
    "    def on_train_batch_end(self, trainer, module, *args, **kwargs):\n",
    "        if self.inner_step%self.frequency==0:\n",
    "            print(' '.join([\"{0}: {1:.4f}\".format(i, float(j)) for i,j in trainer.logged_metrics.items()]))\n",
    "        self.inner_step += 1\n",
    "        self.step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'num_classes': 1000,\n",
    "                'resnet_version': 50,\n",
    "                'train_path': 'pipe:aws s3 cp s3://jbsnyder-sagemaker-us-east/data/imagenet/train/train_{0000..2047}.tar -',\n",
    "                'val_path': 'pipe:aws s3 cp s3://jbsnyder-sagemaker-us-east/data/imagenet/val/val_{0000..0127}.tar -',\n",
    "                'optimizer': 'adamw',\n",
    "                'lr': 1e-3, \n",
    "                'batch_size': 64,\n",
    "                'dataloader_workers': 0}\n",
    "\n",
    "trainer_params = {'accelerator': 'gpu',\n",
    "                  'max_epochs': 4,\n",
    "                  'num_nodes': 1,\n",
    "                  'precision': 16,\n",
    "                #   'callbacks': [PlSageMakerLogger()]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(**model_params)\n",
    "trainer = pl.Trainer(**trainer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = model.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(model.val_dataloader()):\n",
    "    print(len(batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smdebug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
